---

name: mobilenetv2

gops: [0.8]

shapes:
  - [1, 3, 224, 224]

precision: true

model: $(home)/mobilenet_v2_deploy.prototxt
weight: $(home)/mobilenet_v2.caffemodel

mlir_transform:
  model_transform.py
    --model_name $(name)
    --model_def $(model)
    --model_data $(weight)
    --test_input $(root)/dataset/samples/cat.jpg
    --input_shapes [$(shape_param)]
    --resize_dims 224,224
    --mean 123.675,116.28,103.53
    --scale 0.0171,0.0175,0.0174
    --pixel_format rgb
    --test_result $(name)_top_outputs.npz
    --mlir $(workdir)/transformed.mlir

mlir_calibration:
  run_calibration.py $(workdir)/transformed.mlir
    --dataset $(root)/dataset/ILSVRC2012/caliset
    --input_num 100
    -o $(workdir)/$(name).cali_table

deploy:
  - model_deploy.py --mlir $(workdir)/transformed.mlir
      --quantize F32
      --chip $(target)
      --test_input $(workdir)/$(name)_in_f32.npz
      --test_reference $(name)_top_outputs.npz
      --tolerance 0.99,0.99
      --model $(workdir)/$(name)_$(target)_f32.bmodel
  - model_deploy.py --mlir $(workdir)/transformed.mlir
      --quantize INT8
      --calibration_table $(workdir)/$(name).cali_table
      --quantize_table $(home)/q_table
      --quant_input
      --chip $(target)
      --test_input $(workdir)/$(name)_in_f32.npz
      --test_reference $(name)_top_outputs.npz
      --tolerance 0.78,0.25
      --model $(workdir)/$(name)_$(target)_int8_sym.bmodel

dataset:
  image_path: $(imagenet2012_val_set)
  image_label: $(imagenet2012_caffe_val_ground_truth)
  mean: [123.675, 116.28, 103.53]
  scale: [0.0171, 0.0175, 0.0174]
  resize_dims: 256
  size: 224
  trans: true
  bgr2rgb: true

BM1684:
  harness:
    type: topk
    args:
      - name: FP32
        bmodel: $(workdir)/$(name)_$(target)_f32.bmodel
      - name: INT8
        bmodel: $(workdir)/$(name)_$(target)_int8_sym.bmodel

BM1684X:
  +deploy:
    - model_deploy.py  --mlir $(workdir)/transformed.mlir
        --quantize F16
        --chip $(target)
        --test_input $(workdir)/$(name)_in_f32.npz
        --test_reference $(name)_top_outputs.npz
        --tolerance 0.95,0.85
        --model $(workdir)/$(name)_$(target)_f16.bmodel
    - model_deploy.py --mlir $(workdir)/transformed.mlir
        --quantize BF16
        --chip $(target)
        --test_input $(workdir)/$(name)_in_f32.npz
        --test_reference $(name)_top_outputs.npz
        --tolerance 0.95,0.85
        --model $(workdir)/$(name)_$(target)_bf16.bmodel
    - model_deploy.py --mlir $(workdir)/transformed.mlir
        --quantize INT8
        --asymmetric
        --calibration_table $(workdir)/$(name).cali_table
        --quant_input
        --chip $(target)
        --test_input $(workdir)/$(name)_in_f32.npz
        --test_reference $(name)_top_outputs.npz
        --tolerance 0.90,0.60
        --model $(workdir)/$(name)_$(target)_int8_asym.bmodel

  harness:
    type: topk
    args:
      - name: FP32
        bmodel: $(workdir)/$(name)_$(target)_f32.bmodel
      - name: INT8_SYM
        bmodel: $(workdir)/$(name)_$(target)_int8_sym.bmodel
      - name: INT8_ASYM
        bmodel: $(workdir)/$(name)_$(target)_int8_asym.bmodel
      - name: FP16
        bmodel: $(workdir)/$(name)_$(target)_f16.bmodel
      - name: BF16
        bmodel: $(workdir)/$(name)_$(target)_bf16.bmodel
